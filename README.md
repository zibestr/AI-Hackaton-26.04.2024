# Интеллектуальный анализатор обратной связи студентов
> Данный репозиторий является решением команды **ZhимоVики** на хакатоне *Цифровой прорыв 2024: сезон ИИ (ЦФО)*.

## Содержание

- [Установка и запуск проекта](#установка-и-запуск-проекта)
- [Задача](#Задача)
- [Концепция решения](#Концепция-решения)
- [Обработка данных](#Обработка-данных)
- [Реализация проекта](#Реализация-проекта)
- [Запуск проекта](#Запуск-проекта)
- [Результаты реализации проекта](#Результаты-реализации-проекта)
- [Масштабируемость](#Масштабируемость)
- [Используемое ПО](#Используемое-ПО)
- [О команде](#О-команде)

---

## Установка и запуск проекта
### Установка и запуск проекта на Windows
Саня где?
### Установка и запуск проекта на Linux и MacOs
Sanya where?
### Запуск проекта в контейнере

Для запуска проекта нужно скачать Docker. На Linux его можно скачать командой:
```shell
sudo snap install docker
```
Затем склонировать репозиторий:
```shell
git clone https://github.com/zibestr/Feedback-Analytics.git
```
И выполнить сборку приложения:
```shell
sudo docker compose up
```

---

## Задача
> Разработка чат-бота для детализированного анализа и категоризации обратной связи от студентов после вебинаров.

Создать сервис с искусственным интеллектом, способный анализировать и категоризировать обратную связь от студентов **GeekBrains**. Сервис должен автоматически различать информативную и неинформативную обратную связь, выделяя положительные и отрицательные аспекты курса.

Разработать механизм, который поможет образовательной платформе повысить качество обучения, основываясь на конкретных и аналитически обработанных данных.

---

## Концепция решения
### Алгоритмы

#### Предобработка данных:
1. Отзывы пользователей загружаются в .csv файл и передаются на вход алгоритма предобратки данных.
2. Алгоритм объединяет ответы на вопросы в один большой ответ (для каждого пользователя отдельно).
3. Далее алгоритм нормализует полученный текст:
    - убирает символы пунктуации;
    - удаляет неинформативные слова (междометия, предлоги и тд.);
    - приводит все слова в их начальную форму.
4. Алгоритм разбивает полученный текст на токены (отдельные слова) и использует алгоритм BoW (Bag of Words) для представления токенов в числовом виде.

#### Классификация отзывов:
- На каждый отдельный класс используется свой собственный обученный классификатор:
    - Классификация релевантности отзыва: алгоритм *AdaBoost* над решающими деревьями маленькой глубины;
    - Классификация объекта отзыва: алгоритм *The Complement Naive Bayes*;
    - Эмоциональный анализ отзыва: алгоритм *Градиентный бустинг* над решающими деревьями маленькой глубины.

#### Тематическое моделирование:
- Разработан алгоритм для выделения ключевых слов из текста отзыва студента - *Неотрицательное матричное разложение (Non-Negative Matrix Factorization)*, алгоритм способен выделить любое заданное количество ключевых слов из представленного текста.

### Конечный продукт
Реализованный продукт - чат-бот в мессенджере Telegram и веб-сайт с админ панельную, где предоставлены инструменты автоматического формирования аналитики по отзывам учеников о вебинарах.

---

## Обработка данных

### NLP

Для обработки естественного языка используется библиотека с открытым исходным кодом и свободной лицензией - *natasha*. Это библиотека предоставляет возможности для синтаксического, морфологического анализов, разбиение текста на токены, приведение слов в начальную форму (именительный падеж, единственное число, инфинитив и тд).

### Векторизация

Текст преобразуется в токены (отдельные слова), которые переводятся в начальную форму. Для векторизации полученных токенов используется алгоритм *Bag of Words (BoW)* из библиотеки *scikit-learn*. BoW высчитывает частоту встречи отдельного токена во всем тексте и каждому токену подставляют его частоту встречи в заданном тексте.

---

## Реализация проекта

¿Dónde está Sanya?

---

## Запуск проекта

Où se trouve Sanya ?

---

## Результаты реализации проекта

Hvor er Sanya?

---

## Масштабируемость

三亜はどこですか？

---

## Процесс обучения моделей ИИ

Для запуска процесса обучения в модуле **src.tools.fit_models** есть функция **fit**.\
Чтобы запустить процесс обучения, используйте ***код в Jupyter Notebook или Python файле***:
```python
from src.tools.fit_models import fit

fit('<dataset_filename>.csv')
```
---

## Модель ИИ

### Архитектура итогового классификатора
![Best Classifier in the World](/data/model_repr.png "MultiLabelsClassifier")
---

## Стек технологий
+ Язык программирования: [Python 3.10+](https://www.python.org/)
+ [NumPy](https://numpy.org/) - для быстрых вычислений
+ [Pandas](https://pandas.pydata.org/) - для удобного представления табличных данных и работы с ними
+ [natasha](https://natasha.github.io/) - для предварительной обработки естественного (русского) языка
+ [scikit-learn](https://scikit-learn.org/stable/) - для препроцессинга данных и классификации
+ [aiogram](https://aiogram.dev/) - для реализации бота в telegram
+ [Flask](https://flask.palletsprojects.com/en/3.0.x/) - для реализации веб-интерфейса для преподавателей и администраторов

---

## О команде
- [Яшин Данила](https://github.com/zibestr) (Team Lead, ML Engineer)
- [Основин Александр](https://github.com/PyAlexOs) (Full-stack Developer, Documentation)
- [Егоров Леонид](https://github.com/Grander78498) (Data Scientist, DevOps)
- [Корольков Александр](https://github.com/adkorolkov) (Backend, Data Engineer)
